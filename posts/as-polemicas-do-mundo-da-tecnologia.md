---
title: 'As polêmicas do mundo da tecnologia'
date: '2017-01-11T16:13:54+00:00'
author: 'Equipe Descola'
featuredPost: false
templatekey: blog-post
tags:
  - geral
featuredImage: ../static/images/tomada_decisao.jpg
---

Segundo Oliver Usher, os algoritmos e o aprendizado de máquina serão as grandes controvérsias tecnológicas dos próximos anos.

Os **algoritmos de tomada de decisão** compartilham muitas das dificuldades com tecnologias anteriores tão polêmicas quanto esta. Assim como a introdução de cultivos geneticamente modificados, vacinas e o crescimento do poder nuclear – questões muito controversas nas décadas anteriores -, o uso de algoritmos de tomada de decisões envolve uma porção de implicações sociais, combinada com a falta de transparência, de prestação de contas e de poder de escolha por parte dos usuários.

Em 2017, entretanto, o público tende a discutir sobre as decisões que os algoritmos tomam e a maneira com que eles nos afetam. Os debates sobre a sua introdução se tornarão cada vez mais populares.

## O que são algoritmos?

Um **algoritmo** é uma sequência de regras passo-a-passo que estabelece a maneira com que uma decisão é tomada. O conceito existe desde os primórdios da ciência (assim como a própria palavra “algoritmo”), mas foi na metade do século passado que os algoritmos se tornaram tão importantes: os programas de computadores não são nada mais que algoritmos complexos – regras que dizem ao computador como tomar decisões.

**Aprendizado de máquina**, por sua vez, é uma invenção mais recente. Programados para reconhecerem padrões de dados e promoverem resultados desejáveis, os algoritmos de aprendizado de máquina se reescrevem efetivamente – uma forma de inteligência artificial. Em vez de o computador simplesmente implementar as regras que um programador humano escreveu, a máquina descobre a melhor maneira de alcançar um resultado prioritário.

## O grande problema

Num curto espaço de tempo, os algoritmos tomaram o lugar das decisões humanas em muitas partes de nossas vidas. Algumas decisões são boas, outras são ruins. Mas a maneira com que essas decisões são feitas raramente são transparentes.

As pessoas têm muito pouco conhecimento sobre como os softwares proprietários funcionam. No caso dos algoritmos de aprendizado de máquina, é questionado até mesmo se os seus programadores entendem completamente como as decisões são tomadas, dado que os softwares ensinam e aprendem consigo mesmos.

Em um exemplo de erro de aprendizado de máquina, um algoritmo criado para classificar fotos de cães, e não lobos, acabou por aprender a como reconhecer paisagens nevadas. Entretanto, os algoritmos e o aprendizado de máquina estão cada vez tomando decisões que afetam nosso dia-a-dia, muito mais importantes que separar lobos e cachorros.

Na próxima vez que você procurar por um emprego, existe uma boa chance de que pelo menos uma parte da avaliação de admissão seja efetuada por um computador. Se você for processado nos Estados Unidos, é provável que um algoritmo recomende ao juiz se você está liberado ou não sob fiança. Se sua aplicação de hipoteca é aceita, ou você consegue um baixo valor pelo seguro do carro, a decisão muito provavelmente não foi feita por um humano. O protótipo de carros que dirigem sozinhos confiam em algoritmos para tomar decisões de vida ou morte que afetam diretamente seus passageiros, assim como outros usuários da via.

Quando as máquinas tomam as decisões, os preconceitos humanos tendem a ser excluídos, e as decisões, mais justas. Mas não é bem assim que funciona. Um algoritmo de aprendizado que se treinou para identificar candidatos, baseado em como eles são semelhantes aos funcionários bem sucedidos de uma empresa, pode ser uma ótima maneira de eliminar os preconceitos inconscientes dos recrutadores. Mas também pode simplesmente replicar a discriminação da corporação com uma suposta neutralidade tecnológica.

Da mesma forma, existem alegações plausíveis (embora contestadas) de que um algoritmo usado para decidir quem vai para a prisão nos Estados Unidos é mais duro para os criminosos negros do que com os brancos.

## Notícias falsas

Um dos assuntos mais populares do final de 2016 foi o problema das notícias falsas espalhadas pelas mídias sociais.

Algoritmos de curadoria de notícias acabam por gerar falta de transparência sobre quem produz o conteúdo e quem verifica os fatos, levando-nos a questionar se deveríamos acreditar em tudo que lemos.

![noticia-falsa](https://descola.org/drops/wp-content/uploads/2017/01/Screen-Shot-2017-01-10-at-18.49.55.png)

Nestas circunstâncias, não é de surpreender que Donald Trump tenha culpado o algoritmo do Google News pelas falsas notícias (mesmo que o presidente tenha se beneficiado com a popularidade trazida por elas).

## Repercussão

No próximo ano, a repercussão contra as decisões dos algoritmos tomará grandes proporções, e isso ocorrerá de várias formas. Pode ser um político forçado a renunciar devido a notícias falsas trazidas por um algoritmo de notícias; um assassinato cometido por um bandido libertado sob fiança graças a um software judicial; um pedestre que perde a vida atropelado por um carro auto-dirigível. A tomada de decisão através de algoritmos estará na linha de fogo quando o assunto é a vida.

Os profissionais da tecnologia serão forçados a enfrentar as críticas e abordar algumas das preocupações mais óbvias a respeito de transparência e decisões preconceituosas dos algoritmos. Assim como aconteceu com as tecnologias das décadas anteriores, a promessa de que os algoritmos de tomada de decisão tornarão o mundo melhor pode entrar em risco se a resposta exigida a respeito de tais preocupações não for rápida e plausível.

![trust-project](https://descola.org/drops/wp-content/uploads/2017/01/VZpw09Kl.png)O surto de notícias falsas já levou o Facebook e o Google a concentrarem seus esforços a fim de encontrar soluções para esta nova polêmica tecnológica. Da mesma forma, organizações como o [Trust Project](http://thetrustproject.org/) estão buscando produzir tecnologia que classifique de forma independente a confiabilidade dos meios de comunicação que consumimos.

Assim como os clientes estão dispostos a pagar mais por alimentos sem culturas geneticamente modificadas ou pesticidas, se não confiarem nas decisões das máquinas, as pessoas vão ter preferência por decisões tomadas por seres humanos.

_Texto baseado no artigo “[Computer says no: the backlash](http://www.nesta.org.uk/2017-predictions/computer-says-no-backlash)“._
